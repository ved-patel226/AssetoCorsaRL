model:
  # network / optimizer
  num_cells: 256
  lr: 3e-4
  max_grad_norm: 1.0

  gamma: 0.99 # Higher discount factor for better long-term credit assignment
  tau: 0.005 # Slower target updates prevent Q-value divergence (was 0.01)

  # entropy
  alpha: 0.2
  alpha_lr: 3e-4 # Slower alpha learning prevents entropy collapse
  alpha_min: 0.01 # Minimum alpha to maintain exploration

  # replay / training
  batch_size: 512
  replay_size: 600000
  # start_steps: 1000

  load_initial: true

  # noisy nets
  use_noisy: false # Disabled - use epsilon-greedy first
  noise_sigma: 0.5

  # PER
  per_alpha: 0.6
  per_beta: 0.6
